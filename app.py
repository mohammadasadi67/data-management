import streamlit as st
import pandas as pd
import plotly.express as px
from supabase import create_client, Client
from datetime import datetime
import re
import numpy as np

# ==============================================================================
# 0. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ (Configuration & Global Variables)
#    **Ú©Ù„ÛŒØ¯ Service Role Ùˆ URL Ø´Ù…Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§ÛŒÙ†Ø¬Ø§ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯**
# ==============================================================================

st.set_page_config(
    page_title="Ù…Ø¯ÛŒØ±ÛŒØª Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ÛŒ",
    page_icon="âš™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Supabase Configuration (Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ù…Ø¹ØªØ¨Ø± Ø´Ù…Ø§) ---
SUPABASE_URL = "https://rlutsxvghmhrgcnqbmch.supabase.co" 
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InJsdXRzeHZnaG1ocmdjbnFibWNoIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NTEyODk5MSwiZXhwIjoyMDYwNzA0OTkxfQ.VPxJbrPUw4E-MyRGklQMcxveUTznNlWLhPO-mqrHv9c"

ARCHIVE_DELETE_PASSWORD = "beautifulmind" # Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø­Ø°Ù Ø¢Ø±Ø´ÛŒÙˆ Ø´Ù…Ø§

@st.cache_resource
def get_supabase_client():
    """Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ú©Ø´ Ú©Ø±Ø¯Ù† Ø§ØªØµØ§Ù„ Ø¨Ù‡ Supabase."""
    try:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
        return supabase
    except Exception as e:
        # Ø§Ú¯Ø± Ø®Ø·Ø§ Û´Û°Û± ÛŒØ§ PGRST106 Ø§ÛŒÙ†Ø¬Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ØŒ Ù…Ø´Ú©Ù„ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Supabase Ø§Ø³Øª Ù†Ù‡ Ú©Ø¯
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Supabase: {e}")
        st.stop()

supabase = get_supabase_client()

# ==============================================================================
# Û±. ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Helper Functions)
# ==============================================================================

def standardize_columns(df):
    """
    Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ (Ø­Ù„ Ù…Ø´Ú©Ù„ KeyError): Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ØŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Title Case.
    """
    new_columns = {}
    for col in df.columns:
        cleaned_col = re.sub(r'[^\w\s-]', '', str(col)).strip()
        standard_col = cleaned_col.replace(' ', '').title()
        new_columns[col] = standard_col
    return df.rename(columns=new_columns)

def parse_filename_date_to_datetime(filename):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ® Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„."""
    match = re.search(r'(\d{8})', filename)
    if match:
        try:
            return datetime.strptime(match.group(1), '%d%m%Y').date()
        except ValueError:
            return None
    return None

def load_data_from_supabase(table_name="production_data"):
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Supabase Ø¨Ø§ Ú©Ø´."""
    @st.cache_data(ttl=600) 
    def fetch_data():
        try:
            response = supabase.table(table_name).select("*").execute()
            df = pd.DataFrame(response.data)
            
            if df.empty:
                return df
                
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
            
            return standardize_columns(df) 
        except Exception as e:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Supabase: {e}")
            return pd.DataFrame()
    return fetch_data()


def process_uploaded_excel(uploaded_file, selected_sheet_name):
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Production Ùˆ Error.
    """
    try:
        df_raw_sheet = pd.read_excel(uploaded_file, sheet_name=selected_sheet_name, header=None)
        
        # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Production (Ø¨Ø§Ø²Ù‡ D4:P9) ---
        data_prod = df_raw_sheet.iloc[3:9, 3:16].copy()
        headers_prod = df_raw_sheet.iloc[2, 3:16].tolist()
        data_prod.columns = headers_prod
        df_prod = data_prod.melt(ignore_index=False, var_name='ProductionTypeForTon', value_name='ProductionValue').dropna(subset=['ProductionValue'])
        
        
        # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Error (Ø¨Ø§Ø²Ù‡ D13:P15) ---
        data_err = df_raw_sheet.iloc[12:15, 3:16].copy()
        headers_err = df_raw_sheet.iloc[11, 3:16].tolist()
        data_err.columns = headers_err
        df_err = data_err.melt(ignore_index=False, var_name='MachineType', value_name='ErrorDuration').dropna(subset=['ErrorDuration'])


        # --- ØªØ±Ú©ÛŒØ¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ---
        filename = uploaded_file.name
        file_date = parse_filename_date_to_datetime(filename)
        shift = df_raw_sheet.iloc[1, 1].strip() if not pd.isna(df_raw_sheet.iloc[1, 1]) else 'Unknown'
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Metadata Ùˆ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
        df_prod['Date'] = file_date
        df_prod['Shift'] = shift
        df_prod['Filename'] = filename
        df_prod = standardize_columns(df_prod).reset_index(drop=True)

        df_err['Date'] = file_date
        df_err['Shift'] = shift
        df_err['Filename'] = filename
        df_err = standardize_columns(df_err).reset_index(drop=True)

        return df_prod, df_err

    except Exception as e:
        st.error(
            f"""
            âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ '{uploaded_file.name}' (Ø´ÛŒØª: {selected_sheet_name}):
            Ø³Ø§Ø®ØªØ§Ø± Ø´ÛŒØª Ø§Ú©Ø³Ù„ Ù…Ø·Ø§Ø¨Ù‚Øª Ù†Ø¯Ø§Ø±Ø¯. (Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§: {e})
            """
        )
        return pd.DataFrame(), pd.DataFrame()


def upload_to_supabase(df, table_name):
    """Ø¢Ù¾Ù„ÙˆØ¯ DataFrame Ø¨Ù‡ Supabase."""
    if df.empty:
        st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        return False
        
    records = df.to_dict('records')
    try:
        supabase.table(table_name).insert(records).execute()
        return True
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ '{table_name}': {e}")
        return False


# ==============================================================================
# Û². Ø³Ø§Ø®ØªØ§Ø± Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (UI Structure)
# ==============================================================================

# Ø³ØªÙˆÙ† Ú©Ù†Ø§Ø±ÛŒ (Sidebar)
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/1/10/Streamlit_logo.png", width=50) 
    st.title("Ù…Ù†ÙˆÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡")
    st.markdown("---")
    
    if 'page' not in st.session_state:
        st.session_state.page = "Upload"
        
    if st.button("â¬†ï¸ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§", use_container_width=True):
        st.session_state.page = "Upload"
    if st.button("ðŸ“ˆ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„", use_container_width=True):
        st.session_state.page = "Analysis"
    if st.button("ðŸ—„ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ø±Ø´ÛŒÙˆ", use_container_width=True):
        st.session_state.page = "Archive"

    st.markdown("---")
    # ØªÙˆØ¶ÛŒØ­Ø§Øª Ø´Ù…Ø§ Ø§Ø² ÙØ§ÛŒÙ„ test.txt Ø¯Ø± ÛŒÚ© Expander Ø²ÛŒØ¨Ø§
    with st.expander("Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù¾Ù„ØªÙØ±Ù… Ùˆ ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡", expanded=False):
        st.markdown(
            """
            Ø¯Ø± Ø¯Ù†ÛŒØ§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ù…Ø±ÙˆØ²ØŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯ÛŒÚ¯Ø± ÛŒÚ© Ú¯Ø²ÛŒÙ†Ù‡ Ù†ÛŒØ³ØªØŒ Ø¨Ù„Ú©Ù‡ ÛŒÚ© Ø¶Ø±ÙˆØ±Øª Ø§Ø³Øª. 
            Ù…Ù† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªÙˆÙ„ÛŒØ¯ Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ Ø¨Ø§ Ø¹Ù„Ø§Ù‚Ù‡ Ø¨Ù‡ Ù¾Ø§ÛŒØªÙˆÙ†ØŒ Ø§ÛŒÙ† Ù¾Ù„ØªÙØ±Ù… Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Streamlit Ø±Ø§ ØªÙˆØ³Ø¹Ù‡ Ø¯Ø§Ø¯Ù….
            Ø§Ú¯Ø±Ú†Ù‡ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ù…Ù† Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ø¨Ø§ ØªØ¹Ù‡Ø¯ Ùˆ Ú©Ù†Ø¬Ú©Ø§ÙˆÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù…. 
            Ø§Ø² Ø­Ù…Ø§ÛŒØª Ùˆ Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§ÛŒÙ† Ù¾Ù„ØªÙØ±Ù… Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù….
            
            ðŸ“§ **Ø§ÛŒÙ…ÛŒÙ„:** m.asdz@yahoo.com
            """
        )


# ==============================================================================
# Û³. Ù…Ù†Ø·Ù‚ ØµÙØ­Ø§Øª (Page Logic)
# ==============================================================================

if st.session_state.page == "Upload":
    st.header("â¬†ï¸ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ÛŒ")
    st.info("Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ Ø±Ø§ Ø¨Ø§ ÙØ±Ù…Øª **ddmmyyyy** Ø¯Ø± Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")
    st.markdown("---")
    
    col1, col2 = st.columns([1, 2])

    with col1:
        uploaded_files = st.file_uploader(
            "ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ (Daily Production) Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯",
            type=["xlsx"],
            accept_multiple_files=True
        )
        sheet_name = st.text_input("Ù†Ø§Ù… Ø´ÛŒØª (Sheet Name) Ø­Ø§ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:", value="daily")
        upload_button = st.button("Ø´Ø±ÙˆØ¹ Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Supabase", use_container_width=True, type="primary")

    if upload_button and uploaded_files:
        st.subheader("Ù†ØªØ§ÛŒØ¬ Ù¾Ø±Ø¯Ø§Ø²Ø´")
        st.cache_data.clear() 

        total_files = len(uploaded_files)
        success_count = 0
        
        with st.status("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§...", expanded=True) as status:
            for i, file in enumerate(uploaded_files):
                st.write(f"({i+1}/{total_files}) Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: **{file.name}**")
                
                df_prod, df_err = process_uploaded_excel(file, sheet_name)
                
                if df_prod.empty and df_err.empty:
                    st.warning(f"âš ï¸ ÙØ§ÛŒÙ„ **{file.name}** Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯.")
                    continue
                
                upload_prod_success = upload_to_supabase(df_prod, "production_data")
                
                if upload_prod_success: 
                    success_count += 1
                    st.success(f"âœ… ÙØ§ÛŒÙ„ **{file.name}** Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯.")
                else:
                    st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ **{file.name}**.")

            if success_count == total_files:
                status.update(label="âœ… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯!", state="complete", expanded=False)
            else:
                status.update(label=f"âš ï¸ {success_count} Ø§Ø² {total_files} ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯. Ø¬Ø²Ø¦ÛŒØ§Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.", state="warning", expanded=True)
                
        st.rerun()


elif st.session_state.page == "Analysis":
    st.header("ðŸ“ˆ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªÙˆÙ„ÛŒØ¯")
    st.markdown("---")

    df_all = load_data_from_supabase()

    if df_all.empty:
        st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")
    else:
        # Ù†Ø§Ù… Ø³ØªÙˆÙ† Ù¾Ø³ Ø§Ø² Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Productiontypeforton Ø§Ø³Øª
        if 'Productiontypeforton' in df_all.columns and 'Date' in df_all.columns: 
            
            # ÙÛŒÙ„ØªØ±Ù‡Ø§
            col_filt1, col_filt2, col_filt3 = st.columns(3)
            
            with col_filt1:
                min_date = df_all['Date'].min()
                max_date = df_all['Date'].max()
                date_range = st.date_input(
                    "Ù…Ø­Ø¯ÙˆØ¯Ù‡ ØªØ§Ø±ÛŒØ®:",
                    value=(min_date, max_date),
                    min_value=min_date,
                    max_value=max_date
                )
                
            with col_filt2:
                all_products = ['All'] + sorted(df_all['Productiontypeforton'].unique().tolist())
                selected_product = st.selectbox("Ù†ÙˆØ¹ Ù…Ø­ØµÙˆÙ„:", all_products)
                
            # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù†Ù‡Ø§ÛŒÛŒ
            df_filtered = df_all[
                (df_all['Date'] >= date_range[0]) & 
                (df_all['Date'] <= date_range[1])
            ]
            
            if selected_product != 'All':
                df_filtered = df_filtered[df_filtered['Productiontypeforton'] == selected_product]

            st.markdown("### Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯")
            
            # ØªØ¬Ù…ÛŒØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±
            df_chart = df_filtered.groupby(['Date', 'Productiontypeforton'])['Productionvalue'].sum().reset_index()
            
            if not df_chart.empty:
                # Ù†Ù…ÙˆØ¯Ø§Ø± ÙÙˆÙ‚ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø¨Ø§ Plotly
                fig = px.bar(
                    df_chart, 
                    x='Date', 
                    y='Productionvalue', 
                    color='Productiontypeforton',
                    title='ØªÙˆÙ„ÛŒØ¯ ØªØ¬Ù…Ø¹ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ® Ùˆ Ù†ÙˆØ¹ Ù…Ø­ØµÙˆÙ„',
                    labels={'Productionvalue': 'Ù…Ù‚Ø¯Ø§Ø± ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)', 'Date': 'ØªØ§Ø±ÛŒØ®'},
                    height=500,
                    template="plotly_dark" 
                )
                fig.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title="Ù…Ù‚Ø¯Ø§Ø± ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)")
                st.plotly_chart(fig, use_container_width=True)
                
                st.markdown("### Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ (Ø¬Ø²Ø¦ÛŒØ§Øª)")
                st.dataframe(df_filtered, use_container_width=True, hide_index=True)
            else:
                st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        else:
            st.warning("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… (Productiontypeforton ÛŒØ§ Date) Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Supabase Ø´Ù…Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ Ø¬Ø¯ÛŒØ¯ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")


elif st.session_state.page == "Archive":
    st.header("ðŸ—„ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ùˆ Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø±Ø´ÛŒÙˆ")
    st.markdown("---")
    
    st.warning("âš ï¸ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ù‡ Ø´Ù…Ø§ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ØªØ§ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ø¬Ø¯ÙˆÙ„ Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† Ø¹Ù…Ù„ ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ø¨Ø§Ø²Ú¯Ø´Øª Ø§Ø³Øª.")

    table_to_delete = st.selectbox(
        "Ø¬Ø¯ÙˆÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:",
        ["production_data", "error_data"],
        key="archive_table_select"
    )
    
    delete_password = st.text_input("Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø­Ø°Ù:", type="password")
    
    if st.button(f"ðŸ”¥ Ø­Ø°Ù ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ '{table_to_delete}'", type="danger", use_container_width=True):
        if delete_password == ARCHIVE_DELETE_PASSWORD:
            try:
                supabase.table(table_to_delete).delete().neq('id', '0').execute() 
                st.cache_data.clear() 
                st.success(f"âœ… ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ **{table_to_delete}** Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ø°Ù Ø´Ø¯Ù†Ø¯.")
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø­Ø°Ù: {e}")
        else:
            st.error("Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø­Ø°Ù Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª.")
