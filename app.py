import streamlit as st
import pandas as pd
import plotly.express as px
from supabase import create_client, Client
from datetime import datetime, time as datetime_time
from io import BytesIO
import re
import numpy as np

# ==============================================================================
# 0. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ (Configuration & Global Variables)
# ==============================================================================

st.set_page_config(
    page_title="Ù…Ø¯ÛŒØ±ÛŒØª Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ÛŒ",
    page_icon="âš™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ØªØ¹Ø±ÛŒÙ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…Ø­Ø±Ù…Ø§Ù†Ù‡ Ø§Ø² st.secrets
try:
    SUPABASE_URL = st.secrets["supabase_url"]
    SUPABASE_KEY = st.secrets["supabase_key"]
    ARCHIVE_DELETE_PASSWORD = st.secrets["archive_delete_password"]
except KeyError:
    st.error("Ø®Ø·Ø§: Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Supabase ÛŒØ§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø­Ø°Ù Ø¯Ø± Streamlit Secrets ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.")
    st.stop()

@st.cache_resource
def get_supabase_client():
    """Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ú©Ø´ Ú©Ø±Ø¯Ù† Ø§ØªØµØ§Ù„ Ø¨Ù‡ Supabase."""
    try:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
        return supabase
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Supabase: {e}")
        st.stop()

supabase = get_supabase_client()

# ==============================================================================
# Û±. ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Helper Functions)
# ==============================================================================

def standardize_columns(df):
    """
    Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ØŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Title Case Ùˆ Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ù…Ø´Ú©Ù„ 'KeyError: 'MachineType Ø±Ø§ Ø­Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    new_columns = {}
    for col in df.columns:
        # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ØºÛŒØ± Ø§Ù„ÙØ¨Ø§ÛŒÛŒ-Ø¹Ø¯Ø¯ÛŒ Ø¨Ù‡ Ø¬Ø² ÙØ§ØµÙ„Ù‡
        cleaned_col = re.sub(r'[^\w\s-]', '', str(col)).strip()
        # Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Title Case Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
        standard_col = cleaned_col.replace(' ', '').title()
        new_columns[col] = standard_col
    return df.rename(columns=new_columns)

def parse_filename_date_to_datetime(filename):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ® Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¢Ø¨Ø¬Ú©Øª datetime."""
    match = re.search(r'(\d{8})', filename)
    if match:
        try:
            return datetime.strptime(match.group(1), '%d%m%Y').date()
        except ValueError:
            return None
    return None

def load_data_from_supabase(table_name="production_data"):
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Supabase Ø¨Ø§ Ú©Ø´."""
    # st.cache_data Ø¨Ø±Ø§ÛŒ Ú©Ø´ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    @st.cache_data(ttl=600) 
    def fetch_data():
        try:
            response = supabase.table(table_name).select("*").execute()
            df = pd.DataFrame(response.data)
            
            if df.empty:
                return df
                
            # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø² Supabase Ø¨Ù‡ ÙØ±Ù…Øª datetime
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date']).dt.date
            
            return standardize_columns(df)
        except Exception as e:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Supabase: {e}")
            return pd.DataFrame()
    return fetch_data()


def process_uploaded_excel(uploaded_file, selected_sheet_name):
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Production Ùˆ Error.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ØŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ Syntax Ùˆ Indentation Ø±Ø§ Ø¯Ø± ØªÙˆØ§Ø¨Ø¹ ÙØ±Ø¹ÛŒ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    try:
        df_raw_sheet = pd.read_excel(uploaded_file, sheet_name=selected_sheet_name, header=None)
        
        # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Production ---
        # Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø´Ù…Ø§)
        # Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ ØªÙˆØ±ÙØªÚ¯ÛŒ: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªÙˆØ±ÙØªÚ¯ÛŒ ØµØ­ÛŒØ­ Ø¯Ø± Ù…Ø­ÛŒØ· GitHub
        data_prod = df_raw_sheet.iloc[3:9, 3:16].copy()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ø¯Ø±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ… Ù†Ø§Ù… Ø³ØªÙˆÙ†
        headers_prod = df_raw_sheet.iloc[2, 3:16].tolist()
        data_prod.columns = headers_prod
        
        # ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        df_prod = data_prod.melt(ignore_index=False, var_name='ProductionTypeForTon', value_name='ProductionValue').dropna(subset=['ProductionValue'])
        
        
        # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Error ---
        # Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø·Ø§ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø´Ù…Ø§)
        data_err = df_raw_sheet.iloc[12:15, 3:16].copy()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ø¯Ø±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ… Ù†Ø§Ù… Ø³ØªÙˆÙ†
        headers_err = df_raw_sheet.iloc[11, 3:16].tolist()
        data_err.columns = headers_err
        
        # ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        df_err = data_err.melt(ignore_index=False, var_name='MachineType', value_name='ErrorDuration').dropna(subset=['ErrorDuration'])


        # --- ØªØ±Ú©ÛŒØ¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ---
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ÙØ§ÛŒÙ„
        filename = uploaded_file.name
        file_date = parse_filename_date_to_datetime(filename)
        shift = df_raw_sheet.iloc[1, 1].strip() if not pd.isna(df_raw_sheet.iloc[1, 1]) else 'Unknown'
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Metadata Ø¨Ù‡ DataFrame ØªÙˆÙ„ÛŒØ¯
        df_prod['Date'] = file_date
        df_prod['Shift'] = shift
        df_prod['Filename'] = filename
        df_prod = df_prod.reset_index(drop=True)

        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Metadata Ø¨Ù‡ DataFrame Ø®Ø·Ø§
        df_err['Date'] = file_date
        df_err['Shift'] = shift
        df_err['Filename'] = filename
        df_err = df_err.reset_index(drop=True)

        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ (Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø´Ú©Ù„ KeyError Ø±Ø§ Ø­Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
        df_prod = standardize_columns(df_prod)
        df_err = standardize_columns(df_err)

        return df_prod, df_err

    except Exception as e:
        # Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ SyntaxError Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Triple Quotes
        st.error(
            f"""
            Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ '{uploaded_file.name}' (Ø´ÛŒØª: {selected_sheet_name}):
            Ø³Ø§Ø®ØªØ§Ø± Ø´ÛŒØª Ø§Ú©Ø³Ù„ Ù…Ø·Ø§Ø¨Ù‚Øª Ù†Ø¯Ø§Ø±Ø¯. (Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§: {e})
            Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ù‡Ø¯Ø±Ù‡Ø§ Ùˆ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ø¬Ø§ÛŒ ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯.
            """
        )
        return pd.DataFrame(), pd.DataFrame()


def upload_to_supabase(df, table_name):
    """Ø¢Ù¾Ù„ÙˆØ¯ DataFrame Ø¨Ù‡ Supabase."""
    if df.empty:
        st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        return False
        
    # Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚ØªÛŒ Ú©Ù‡ Ø¯Ø± Supabase Ù†ÛŒØ³ØªÙ†Ø¯ (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯)
    df_upload = df.copy()
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯
    records = df_upload.to_dict('records')
    try:
        supabase.table(table_name).insert(records).execute()
        return True
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ '{table_name}': {e}")
        return False


# ==============================================================================
# Û². Ø³Ø§Ø®ØªØ§Ø± Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (UI Structure)
# ==============================================================================

# Ø³ØªÙˆÙ† Ú©Ù†Ø§Ø±ÛŒ (Sidebar)
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/1/10/Streamlit_logo.png", width=50) # 
    st.title("Ù…Ù†ÙˆÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡")
    st.markdown("---")
    
    # Ú©Ù†ØªØ±Ù„ ØµÙØ­Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Session State (Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ)
    if 'page' not in st.session_state:
        st.session_state.page = "Upload"
        
    if st.button("â¬†ï¸ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§", use_container_width=True):
        st.session_state.page = "Upload"
    if st.button("ðŸ“ˆ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„", use_container_width=True):
        st.session_state.page = "Analysis"
    if st.button("ðŸ—„ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ø±Ø´ÛŒÙˆ", use_container_width=True):
        st.session_state.page = "Archive"

    st.markdown("---")
    # ØªÙˆØ¶ÛŒØ­Ø§Øª Ùˆ ØªÙ…Ø§Ø³ (Ù…Ø§Ù†Ù†Ø¯ Ø¨Ø®Ø´ Contact Me Ø¯Ø± Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ Ø´Ù…Ø§)
    st.markdown("Developed by M. Asadollahzadeh")
    st.markdown("ðŸ“§ Email: m.asdz@yahoo.com")


# ==============================================================================
# Û³. Ù…Ù†Ø·Ù‚ ØµÙØ­Ø§Øª (Page Logic)
# ==============================================================================

if st.session_state.page == "Upload":
    st.header("â¬†ï¸ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ÛŒ")
    st.markdown("---")
    
    col1, col2 = st.columns([1, 2])

    with col1:
        uploaded_files = st.file_uploader(
            "ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ (Daily Production) Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯",
            type=["xlsx"],
            accept_multiple_files=True
        )
        sheet_name = st.text_input("Ù†Ø§Ù… Ø´ÛŒØª (Sheet Name) Ø­Ø§ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:", value="daily")
        upload_button = st.button("Ø´Ø±ÙˆØ¹ Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Supabase", use_container_width=True, type="primary")

    if upload_button and uploaded_files:
        st.subheader("Ù†ØªØ§ÛŒØ¬ Ù¾Ø±Ø¯Ø§Ø²Ø´")
        
        # Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´ Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯ Ø¬Ø¯ÛŒØ¯
        st.cache_data.clear() 

        total_files = len(uploaded_files)
        success_count = 0
        
        with st.status("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§...", expanded=True) as status:
            for i, file in enumerate(uploaded_files):
                st.write(f"({i+1}/{total_files}) Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: **{file.name}**")
                
                # Û±. Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„
                df_prod, df_err = process_uploaded_excel(file, sheet_name)
                
                if df_prod.empty and df_err.empty:
                    st.warning(f"âš ï¸ ÙØ§ÛŒÙ„ **{file.name}** Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯. (Ø¨Ù‡ Ù„Ø§Ú¯ Ø®Ø·Ø§ ØªÙˆØ¬Ù‡ Ú©Ù†ÛŒØ¯)")
                    continue
                
                # Û². Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯
                upload_prod_success = upload_to_supabase(df_prod, "production_data")
                
                # Û³. Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø·Ø§ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ: Ø§Ú¯Ø± Ø¬Ø¯ÙˆÙ„ error_data Ø¯Ø± Supabase Ø¯Ø§Ø±ÛŒØ¯)
                # upload_err_success = upload_to_supabase(df_err, "error_data") 
                
                if upload_prod_success: # and upload_err_success:
                    success_count += 1
                    st.success(f"âœ… ÙØ§ÛŒÙ„ **{file.name}** Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯.")
                else:
                    st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ **{file.name}**.")

            if success_count == total_files:
                status.update(label="âœ… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯!", state="complete", expanded=False)
            else:
                status.update(label=f"âš ï¸ {success_count} Ø§Ø² {total_files} ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯. Ø¬Ø²Ø¦ÛŒØ§Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.", state="warning", expanded=True)
                
        # Clear the file uploader after processing
        st.rerun()


elif st.session_state.page == "Analysis":
    st.header("ðŸ“ˆ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªÙˆÙ„ÛŒØ¯")
    st.markdown("---")

    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´
    df_all = load_data_from_supabase()

    if df_all.empty:
        st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")
    else:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ±Ù‡Ø§
        
        # Û±. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ (Ù¾Ø³ Ø§Ø² Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ)
        if 'ProductionTypeForTon' in df_all.columns and 'Date' in df_all.columns:
            
            # ÙÛŒÙ„ØªØ±Ù‡Ø§
            col_filt1, col_filt2, col_filt3 = st.columns(3)
            
            with col_filt1:
                min_date = df_all['Date'].min()
                max_date = df_all['Date'].max()
                date_range = st.date_input(
                    "Ù…Ø­Ø¯ÙˆØ¯Ù‡ ØªØ§Ø±ÛŒØ®:",
                    value=(min_date, max_date),
                    min_value=min_date,
                    max_value=max_date
                )
                
            with col_filt2:
                all_products = ['All'] + sorted(df_all['ProductionTypeForTon'].unique().tolist())
                selected_product = st.selectbox("Ù†ÙˆØ¹ Ù…Ø­ØµÙˆÙ„:", all_products)
                
            # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù†Ù‡Ø§ÛŒÛŒ
            df_filtered = df_all[
                (df_all['Date'] >= date_range[0]) & 
                (df_all['Date'] <= date_range[1])
            ]
            
            if selected_product != 'All':
                df_filtered = df_filtered[df_filtered['ProductionTypeForTon'] == selected_product]

            st.markdown("### Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯")
            
            # ØªØ¬Ù…ÛŒØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±
            df_chart = df_filtered.groupby(['Date', 'ProductionTypeForTon'])['ProductionValue'].sum().reset_index()
            
            if not df_chart.empty:
                # Ù†Ù…ÙˆØ¯Ø§Ø± ÙÙˆÙ‚ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø¨Ø§ Plotly
                fig = px.bar(
                    df_chart, 
                    x='Date', 
                    y='ProductionValue', 
                    color='ProductionTypeForTon',
                    title='ØªÙˆÙ„ÛŒØ¯ ØªØ¬Ù…Ø¹ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ® Ùˆ Ù†ÙˆØ¹ Ù…Ø­ØµÙˆÙ„',
                    labels={'ProductionValue': 'Ù…Ù‚Ø¯Ø§Ø± ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)', 'Date': 'ØªØ§Ø±ÛŒØ®'},
                    height=500,
                    template="plotly_dark" # ØªÙ… ØªÛŒØ±Ù‡ Ø¨Ø±Ø§ÛŒ UI Ø¬Ø°Ø§Ø¨
                )
                fig.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title="Ù…Ù‚Ø¯Ø§Ø± ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)")
                st.plotly_chart(fig, use_container_width=True)
                
                st.markdown("### Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ (Ø¬Ø²Ø¦ÛŒØ§Øª)")
                st.dataframe(df_filtered, use_container_width=True, hide_index=True)
            else:
                st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        else:
            st.warning("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… (ProductionTypeForTon ÛŒØ§ Date) Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Supabase Ø´Ù…Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")


elif st.session_state.page == "Archive":
    st.header("ðŸ—„ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ùˆ Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø±Ø´ÛŒÙˆ")
    st.markdown("---")
    
    st.warning("Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ù‡ Ø´Ù…Ø§ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ØªØ§ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ø¬Ø¯ÙˆÙ„ Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† Ø¹Ù…Ù„ ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ø¨Ø§Ø²Ú¯Ø´Øª Ø§Ø³Øª.")

    table_to_delete = st.selectbox(
        "Ø¬Ø¯ÙˆÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:",
        ["production_data", "error_data"], # Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ù†Ø§Ù… Ø¬Ø¯Ø§ÙˆÙ„ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
        key="archive_table_select"
    )
    
    delete_password = st.text_input("Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø­Ø°Ù:", type="password")
    
    if st.button(f"Ø­Ø°Ù ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ '{table_to_delete}'", type="danger", use_container_width=True):
        if delete_password == ARCHIVE_DELETE_PASSWORD:
            try:
                # Ø¯Ø³ØªÙˆØ± Ø­Ø°Ù ØªÙ…Ø§Ù… Ø³Ø·Ø±Ù‡Ø§
                supabase.table(table_to_delete).delete().neq('id', '0').execute()
                # Ø­Ø°Ù Ú©Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ Ø±ÙˆØ² Ø±Ø³Ø§Ù†ÛŒ Ø³Ø±ÛŒØ¹ UI
                st.cache_data.clear() 
                st.success(f"âœ… ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ **{table_to_delete}** Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ø°Ù Ø´Ø¯Ù†Ø¯.")
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø­Ø°Ù: {e}")
        else:
            st.error("Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø­Ø°Ù Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª.")
            
# ==============================================================================
# Û´. Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¬Ø¯Ø¯ (Rerun) Ø¨Ø±Ø§ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³Ø±ÛŒØ¹
# ==============================================================================
# Ø§ÛŒÙ† Ø®Ø· Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø± ÛŒÚ© Ø±Ø§Ù† Ø³Ø±ÛŒØ¹ Ù…ÙÛŒØ¯ Ø§Ø³Øª
if st.session_state.get('rerun_after_upload'):
    st.session_state.rerun_after_upload = False
    st.experimental_rerun()
